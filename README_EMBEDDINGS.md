# Generating Embeddings for Microbiome Data

A guide to generate DNA and microbiome embeddings using the `generate_embeddings.py` script.

## What This Does

Converts microbiome sample data into embeddings (numerical representations) that can be used for machine learning:
1. **DNA embeddings** - Using ProkBERT model on bacterial DNA sequences
2. **Microbiome embeddings** - Using a transformer model to create sample-level representations

---

## Step 0: Set Up Python Environment

This project uses [uv](https://docs.astral.sh/uv/) for fast dependency management.

### Install uv (if not already installed)

```bash
# On macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Or with pip
pip install uv
```

### Create and sync the virtual environment

```bash
# Create virtual environment and install all dependencies
uv sync

```

### Activate the environment

```bash
source .venv/bin/activate
```

You should see `(diabimmune-example)` in your terminal prompt.

**Note:** After running `uv sync`, you only need to activate the environment with `source .venv/bin/activate` in future sessions.

---

## Step 1: Download Required Files

### 1.1 Download Parquet Files (Reference Mappings)

ðŸ“¥ **Link:** https://drive.google.com/drive/folders/1d33c5JtZREoDWRAu14o-fDXOpuriuyQC

Download these two files:
- `samples-otus-97.parquet`
- `otus_97_to_dna.parquet`

ðŸ“‚ **Place them in:** `data_preprocessing/mapref_data/`

```
data_preprocessing/
â””â”€â”€ mapref_data/
    â”œâ”€â”€ samples-otus-97.parquet
    â””â”€â”€ otus_97_to_dna.parquet
```

---

### 1.2 Download Model and Data Files

ðŸ“¥ **Link:** https://figshare.com/articles/dataset/Model_and_Data_for_diabimmune_example/30429055?file=58993825

Download these three files:
- `checkpoint_epoch_0_final_epoch3_conf00.pt` (9.3 MB) - Trained model
- `prokbert_embeddings.h5` (640 MB) - Pre-computed OTU embeddings
- `samples-otus.97.metag.minfilter.minCov90.noMulticell.rod2025companion.biom` (8.9 GB) - Sample-OTU mappings

ðŸ“‚ **Place them in:** `data/`

```
data/
â”œâ”€â”€ checkpoint_epoch_0_final_epoch3_conf00.pt
â”œâ”€â”€ prokbert_embeddings.h5
â””â”€â”€ samples-otus.97.metag.minfilter.minCov90.noMulticell.rod2025companion.biom
```

---

### 1.3 Download Your Dataset

ðŸ“¥ **Link:** https://drive.google.com/drive/folders/1-MM3xOOhaEgILnD-D9IiLBrSBQOlz6QP?usp=sharing

This contains folders for different datasets (goldberg, diabumine, etc.).

**For Goldberg dataset:**
1. Open the `goldberg` folder
2. Download the CSV files (T1.csv, T2.csv, T3.csv)

ðŸ“‚ **Place them in:** `data_preprocessing/datasets_preprocessing_scripts/goldberg/`

```
data_preprocessing/
â””â”€â”€ datasets_preprocessing_scripts/
    â””â”€â”€ goldberg/
        â”œâ”€â”€ T1.csv
        â”œâ”€â”€ T2.csv
        â””â”€â”€ T3.csv
```

**CSV Format:**
```csv
Trial,sid,label
T1,ERS4516182,1
T1,ERS4516184,0
```
- `Trial` - Dataset identifier (T1, T2, T3)
- `sid` - Sample ID
- `label` - Classification target (0 or 1)

---

## Step 2: Configure the Script

Open `generate_embeddings.py` and update the **dataset path** at the bottom:

```python
# Line 203-204 in generate_embeddings.py
BASE_OUTPUT_DIR = Path("generated_embeddings")
DATASET_DIR = Path("data_preprocessing/datasets_preprocessing_scripts/goldberg")  # Change this path!
```

**Change `DATASET_DIR`** to point to your dataset folder:
- For Goldberg: `"data_preprocessing/datasets_preprocessing_scripts/goldberg"`
- For other datasets: `"data_preprocessing/datasets_preprocessing_scripts/your_dataset_name"`

---

## Step 3: Run the Script

### Activate your Python environment:
```bash
source .venv/bin/activate
```

### Run the embedding generation:
```bash
python generate_embeddings.py
```

---

## What Happens During Execution

The script processes each CSV file in your dataset folder:

### For each CSV file (e.g., T1.csv, T2.csv, T3.csv):

1. âœ… **Loads sample IDs** from the CSV file
2. âœ… **Generates DNA CSVs** - Extracts DNA sequences for each sample
3. âœ… **Generates DNA embeddings** - Uses ProkBERT model (SLOW - takes hours)
4. âœ… **Generates Microbiome embeddings** - Uses transformer model
5. âœ… **Verifies output** - Sanity check on generated embeddings

### Progress Example:
```
Processing dataset: data_preprocessing/datasets_preprocessing_scripts/goldberg/T1.csv
  Found 261 samples
  Generating DNA CSVs in generated_embeddings/sequences/goldberg/T1...
  Generating DNA embeddings H5 in generated_embeddings/dna_embeddings/goldberg/T1...
  Processing SRS samples: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 261/261 [2:15:30<00:00, 31.23s/it]
  Generating Microbiome embeddings H5 in generated_embeddings/microbiome_embeddings/goldberg/T1...
  âœ“ Data sanity check passed
```

---

## Output Files

All outputs are saved in `generated_embeddings/`:

```
generated_embeddings/
â”œâ”€â”€ sequences/
â”‚   â””â”€â”€ goldberg/
â”‚       â”œâ”€â”€ T1/
â”‚       â”‚   â”œâ”€â”€ ERS4516182.csv
â”‚       â”‚   â””â”€â”€ ... (one CSV per sample)
â”‚       â”œâ”€â”€ T2/
â”‚       â””â”€â”€ T3/
â”œâ”€â”€ dna_embeddings/
â”‚   â””â”€â”€ goldberg/
â”‚       â”œâ”€â”€ T1/
â”‚       â”‚   â””â”€â”€ dna_embeddings.h5
â”‚       â”œâ”€â”€ T2/
â”‚       â”‚   â””â”€â”€ dna_embeddings.h5
â”‚       â””â”€â”€ T3/
â”‚           â””â”€â”€ dna_embeddings.h5
â””â”€â”€ microbiome_embeddings/
    â””â”€â”€ goldberg/
        â”œâ”€â”€ T1/
        â”‚   â””â”€â”€ microbiome_embeddings.h5
        â”œâ”€â”€ T2/
        â”‚   â””â”€â”€ microbiome_embeddings.h5
        â””â”€â”€ T3/
            â””â”€â”€ microbiome_embeddings.h5
```

The `.h5` files contain embeddings for each sample that can be used for machine learning.

---

## Important Notes

### â¸ï¸ Resume Capability
**You can safely interrupt and restart!**

If you press Ctrl+C to stop:
- Already generated files are kept
- When you restart, it skips completed steps
- Only continues with unfinished work

Example:
```
  DNA CSVs already exist at generated_embeddings/sequences/goldberg/T3, skipping generation
  DNA embeddings already exist at generated_embeddings/dna_embeddings/goldberg/T3/dna_embeddings.h5, skipping generation
```

âš ï¸ **IMPORTANT - Incomplete File Warning:**

The script checks if embedding files (`.h5`) **exist**, but NOT if they are **complete**.

**If you interrupt DURING embedding generation** (while it's actively processing samples), you may have an incomplete `.h5` file. The script will see it exists and skip regeneration.

**Solution:**
If you interrupted during embedding generation (not between datasets), delete the incomplete file:

```bash
# If interrupted during DNA embeddings for T1:
rm generated_embeddings/dna_embeddings/goldberg/T1/dna_embeddings.h5

# If interrupted during Microbiome embeddings for T1:
rm generated_embeddings/microbiome_embeddings/goldberg/T1/microbiome_embeddings.h5

# Then restart the script
python generate_embeddings.py
```

**Safe interruption points:**
- âœ… Between CSV files (T1 â†’ T2 â†’ T3)
- âœ… Between steps (DNA CSVs â†’ DNA embeddings â†’ Microbiome embeddings)
- âŒ UNSAFE: During sample processing (shows progress bar like `100/261 [00:30<01:15]`)


ðŸ’¡ **Tip:** If you have a GPU, edit line 23 in `generate_embeddings.py`:
```python
DEVICE = "cuda"  # Change from "cpu" to "cuda"

```
This can be 5-10x faster!

---

## Troubleshooting

### âŒ Error: "No such file or directory: otus_97_to_dna.parquet"
**Problem:** Parquet files not found

**Solution:** Make sure you downloaded and placed the parquet files in `data_preprocessing/mapref_data/`

---

### âŒ Error: "No CSV files found in generated_embeddings/sequences/..."
**Problem:** DNA CSV generation failed (usually due to missing parquet files)

**Solution:**
1. Delete the `generated_embeddings/` folder
2. Make sure parquet files are in the correct location
3. Run the script again

---

### âŒ Out of Memory Error
**Problem:** Not enough RAM

**Solution:** Reduce batch size in `generate_embeddings.py` (line 22):
```python
BATCH_SIZE = 4  # Change from 8 to 4 or 2
```

---

### âš ï¸ Warning: "Some weights of ProkBertModel were not initialized..."
**This is normal!** You can safely ignore this warning.

---

## Complete Directory Structure

After downloading everything, your project should look like this:

```
gut_microbiome_project/
â”œâ”€â”€ generate_embeddings.py          # Main script
â”œâ”€â”€ data_loading.py                 # Helper functions
â”œâ”€â”€ README_EMBEDDINGS.md            # This file
â”‚
â”œâ”€â”€ data/                           # Downloaded model files
â”‚   â”œâ”€â”€ checkpoint_epoch_0_final_epoch3_conf00.pt
â”‚   â”œâ”€â”€ prokbert_embeddings.h5
â”‚   â””â”€â”€ samples-otus.97.metag.minfilter.minCov90.noMulticell.rod2025companion.biom
â”‚
â”œâ”€â”€ data_preprocessing/
â”‚   â”œâ”€â”€ mapref_data/               # Downloaded parquet files
â”‚   â”‚   â”œâ”€â”€ samples-otus-97.parquet
â”‚   â”‚   â””â”€â”€ otus_97_to_dna.parquet
â”‚   â”‚
â”‚   â””â”€â”€ datasets_preprocessing_scripts/
â”‚       â””â”€â”€ goldberg/              # Your dataset CSV files
â”‚           â”œâ”€â”€ T1.csv
â”‚           â”œâ”€â”€ T2.csv
â”‚           â””â”€â”€ T3.csv
â”‚
â””â”€â”€ generated_embeddings/          # Output (created automatically)
    â”œâ”€â”€ sequences/
    â”œâ”€â”€ dna_embeddings/
    â””â”€â”€ microbiome_embeddings/
```

For more details, see `data_loading.py` and `generate_embeddings.py` source code.